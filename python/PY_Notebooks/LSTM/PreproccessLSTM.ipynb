{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000d1a04",
   "metadata": {},
   "source": [
    "<h1>Pre-proccessing data into keyword strings</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5473a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/opt/anaconda3/envs/fp/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from keybert import KeyBERT\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929b3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train_40k.csv')\n",
    "# set to cat1 for 6 topics with 2500 entires each\n",
    "# change call cat1 to Cat2, and replace 2500 with 1000 to create 15 topic model.\n",
    "df = df[['Text', 'Cat1']]\n",
    "df = df[df.groupby('Cat1').Cat1.transform('count')>2500].copy()\n",
    "\n",
    "data = df.values.tolist()\n",
    "\n",
    "# creates a dictionary of all usable topics \n",
    "df_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    df_dict.update({row['Cat1']: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc51a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(df_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a50ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grocery gourmet food': 0, 'toys games': 0, 'beauty': 0, 'health personal care': 0, 'baby products': 0, 'pet supplies': 0}\n"
     ]
    }
   ],
   "source": [
    "print(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be84f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3be77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to new CSV\n",
    "def writeToFile(sen):\n",
    "    with open('sens13.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [sen]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a456ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyBERT keyword extraction and sentence generation\n",
    "def processSen(doc, topic):\n",
    "    keywords = kw_model.extract_keywords(doc, stop_words='english');\n",
    "    keywordsSen = ''\n",
    "    keywords.reverse()\n",
    "    for index, tuple in enumerate(keywords):\n",
    "        keywordsSen += tuple[0]\n",
    "        keywordsSen += ' '\n",
    "    keywordsSen += topic\n",
    "    writeToFile(keywordsSen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68365c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(df_dict)*2500\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36400b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "total = len(df_dict)*2500\n",
    "count = 0\n",
    "for sentence in data:\n",
    "    doc = sentence[0]\n",
    "    label = sentence[1]\n",
    "    # Adds - to topic incase topic isnt a single word. This way the entire topic title is included\n",
    "    topic = sentence[1].replace(\" \", \"-\")\n",
    "    # Checks the text is longer than 10 words and the count for that topic is less than 2500\n",
    "    if((len(doc.split()) > 10) and (df_dict[label] < 2500)): \n",
    "        # proccesses senteence with keybert and writes to CSV\n",
    "        # increases count for topic in df_dict\n",
    "        df_dict[sentence[1]] = df_dict[sentence[1]]+1\n",
    "        count = count + 1\n",
    "        processSen(doc, topic)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    if(count>=total):\n",
    "        break\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
